% Bibliography for comp814.tex
% This file contains all references in BibTeX format
% Each entry has a unique key that can be cited in the LaTeX document using \cite{key}

@inproceedings{schler2006effects,
  title={Effects of age and gender on blogging.},
  author={Schler, Jonathan and Koppel, Moshe and Argamon, Shlomo and Pennebaker, James W},
  booktitle={AAAI spring symposium: Computational approaches to analyzing weblogs},
  volume={6},
  pages={199--205},
  year={2006}
}


@inproceedings{nahrstedt2024empirical,
  title={An Empirical Study on the Energy Usage and Performance of Pandas and Polars Data Analysis Python Libraries},
  author={Nahrstedt, Felix and Karmouche, Mehdi and Bargie{\l}, Karolina and Banijamali, Pouyeh and Nalini Pradeep Kumar, Apoorva and Malavolta, Ivano},
  booktitle={Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
  pages={58--68},
  year={2024}
}

@article{alves2021evolution,
  title={The evolution of the internet and social media: A literature review},
  author={Alves de Castro, Charles and Carthy, Aiden and others},
  year={2021},
  publisher={Technological University Dublin}
}

@article{zabotnova2018internet,
  title={Internet Slang as Key means of Interaction in Cyberspace},
  author={Zabotnova, Myroslava and Bohdanova, OV},
  journal={Development of Philological Sciences in Countries of the European Union taking into Account the Challenges of XXI Century},
  pages={146--64},
  year={2018}
}

@article{detelich2019large,
  title={Large-Scale Date Normalization in ArchivesSpace with Python, MySQL, and Timetwister},
  author={Detelich, Alicia},
  journal={Code4Lib Journal},
  number={44},
  year={2019}
}

@inproceedings{gargova2022evaluation,
  title={Evaluation of Off-the-Shelf Language Identification Tools on Bulgarian Social Media Posts},
  author={Gargova, Silvia and Temnikova, Irina and Dzhumerov, Ivo and Nikolaeva, Hristiana},
  booktitle={Proceedings of the 5th International Conference on Computational Linguistics in Bulgaria (CLIB 2022)},
  pages={152--161},
  year={2022}
}

@article{hacohen2020influence,
  title={The influence of preprocessing on text classification using a bag-of-words representation},
  author={HaCohen-Kerner, Yaakov and Miller, Daniel and Yigal, Yair},
  journal={PloS one},
  volume={15},
  number={5},
  pages={e0232525},
  year={2020},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{bird2006nltk,
  title={NLTK: the natural language toolkit},
  author={Bird, Steven},
  booktitle={Proceedings of the COLING/ACL 2006 interactive presentation sessions},
  pages={69--72},
  year={2006}
}

@inproceedings{sanchez2019sentence,
  title={Sentence boundary detection in legal text},
  author={Sanchez, George},
  booktitle={Proceedings of the natural legal language processing workshop 2019},
  pages={31--38},
  year={2019}
}

@inproceedings{yogish2019review,
  title={Review on natural language processing trends and techniques using NLTK},
  author={Yogish, Deepa and Manjunath, TN and Hegadi, Ravindra S},
  booktitle={Recent Trends in Image Processing and Pattern Recognition: Second International Conference, RTIP2R 2018, Solapur, India, December 21--22, 2018, Revised Selected Papers, Part III 2},
  pages={589--606},
  year={2019},
  organization={Springer}
}

@article{khyani2021interpretation,
  title={An interpretation of lemmatization and stemming in natural language processing},
  author={Khyani, Divya and Siddhartha, BS and Niveditha, NM and Divya, BM},
  journal={Journal of University of Shanghai for Science and Technology},
  volume={22},
  number={10},
  pages={350--357},
  year={2021}
}

@inproceedings{reimers2019sentence,
  title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
  author = "Reimers, Nils and Gurevych, Iryna",
  booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
  month = "11",
  year = "2019",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/1908.10084",
}

@inproceedings{rehurek2010software,
      title = {{Software Framework for Topic Modelling with Large Corpora}},
      author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
      booktitle = {{Proceedings of the LREC 2010 Workshop on New
           Challenges for NLP Frameworks}},
      pages = {45--50},
      year = 2010,
      month = May,
      day = 22,
      publisher = {ELRA},
      address = {Valletta, Malta},
      note={\url{http://is.muni.cz/publication/884893/en}},
      language={English}
}

@article{laureate2023systematic,
  title={A systematic review of the use of topic models for short text social media analysis},
  author={Laureate, Caitlin Doogan Poet and Buntine, Wray and Linger, Henry},
  journal={Artificial Intelligence Review},
  volume={56},
  number={12},
  pages={14223--14255},
  year={2023},
  publisher={Springer}
}

@article{pedregosa2011scikit,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@misc{iabContentTaxonomy,
	author = {},
	title = {{C}ontent {T}axonomy --- iab.com},
	howpublished = {\url{https://www.iab.com/guidelines/content-taxonomy/}},
	year = {},
	note = {[Accessed 10-06-2025]},
}

@inproceedings{frolov2021using,
  title={Using the IAB Contents Taxonomy and Optimal Lifting for Efficient Audience Extension},
  author={Frolov, Dmitry and Taran, Zina and Mirkin, Boris},
  booktitle={International Conference on Intelligent and Fuzzy Systems},
  pages={596--603},
  year={2021},
  organization={Springer}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@inproceedings{schnabel-etal-2015-evaluation,
    title = "Evaluation methods for unsupervised word embeddings",
    author = "Schnabel, Tobias  and
      Labutov, Igor  and
      Mimno, David  and
      Joachims, Thorsten",
    editor = "M{\`a}rquez, Llu{\'i}s  and
      Callison-Burch, Chris  and
      Su, Jian",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D15-1036/",
    doi = "10.18653/v1/D15-1036",
    pages = "298--307"
}

@inproceedings{barbieri-etal-2020-tweeteval,
    title = "{T}weet{E}val: Unified Benchmark and Comparative Evaluation for Tweet Classification",
    author = "Barbieri, Francesco  and
      Camacho-Collados, Jose  and
      Espinosa Anke, Luis  and
      Neves, Leonardo",
    editor = "Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.148/",
    doi = "10.18653/v1/2020.findings-emnlp.148",
    pages = "1644--1650",
    abstract = "The experimental landscape in natural language processing for social media is too fragmented. Each year, new shared tasks and datasets are proposed, ranging from classics like sentiment analysis to irony detection or emoji prediction. Therefore, it is unclear what the current state of the art is, as there is no standardized evaluation protocol, neither a strong set of baselines trained on such domain-specific data. In this paper, we propose a new evaluation framework (TweetEval) consisting of seven heterogeneous Twitter-specific classification tasks. We also provide a strong set of baselines as starting point, and compare different language modeling pre-training strategies. Our initial experiments show the effectiveness of starting off with existing pre-trained generic language models, and continue training them on Twitter corpora."
}

@inproceedings{zhelezniak-etal-2019-correlation,
    title = "Correlation Coefficients and Semantic Textual Similarity",
    author = "Zhelezniak, Vitalii  and
      Savkov, Aleksandar  and
      Shen, April  and
      Hammerla, Nils",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1100/",
    doi = "10.18653/v1/N19-1100",
    pages = "951--962",
    abstract = "A large body of research into semantic textual similarity has focused on constructing state-of-the-art embeddings using sophisticated modelling, careful choice of learning signals and many clever tricks. By contrast, little attention has been devoted to similarity measures between these embeddings, with cosine similarity being used unquestionably in the majority of cases. In this work, we illustrate that for all common word vectors, cosine similarity is essentially equivalent to the Pearson correlation coefficient, which provides some justification for its use. We thoroughly characterise cases where Pearson correlation (and thus cosine similarity) is unfit as similarity measure. Importantly, we show that Pearson correlation is appropriate for some word vectors but not others. When it is not appropriate, we illustrate how common non-parametric rank correlation coefficients can be used instead to significantly improve performance. We support our analysis with a series of evaluations on word-level and sentence-level semantic textual similarity benchmarks. On the latter, we show that even the simplest averaged word vectors compared by rank correlation easily rival the strongest deep representations compared by cosine similarity."
}

@InProceedings{kgosietsile2025cosine,
author="Kgosietsile, Tefo",
editor="Noor, Arti
and Saroha, Kriti
and Pricop, Emil
and Sen, Abhijit
and Trivedi, Gaurav",
title="Cosine Similarity Preserving Curse of Dimensionality Reduction for Managing Computational Complexity",
booktitle="Emerging Trends and Technologies on Intelligent Systems",
year="2025",
publisher="Springer Nature Singapore",
address="Singapore",
pages="253--265",
abstract="High dimensional data in information retrieval and text mining is increasingly in demand. Information retrieval mechanisms in vector databases are performing well in managing high dimensional data. However, data sparsity remains a significant reoccurring issue forcing the data field to resort to traditional data retrieval, which eventually results in an increased curse of dimensionality. An elevated level of the curse of dimensionality eventually produces models that suffer from computational complexity. Data sparsity, being the root cause of the problem, occurs when data points are farther apart and therefore difficult to measure their similarity. It is on this premise that most conversational platforms are suffering from data hallucinations and unjustified responses throughout the search retrieval process. The curse of dimensionality has also been reoccurring in most high dimensional data retrieval systems despite the quite impressive performance of vectors. The prevalence of exponential increase in dimensions poses processing as well as analysis challenges which equates to computational complexity. To address this, reduction mechanisms are the core possible solutions. This research investigates the effectiveness of similarity metrics to aid dimensionality reduction, all in pursuit of managing computational complexity. We therefore designed a test plan to assess the suitability of various similarity metrics and compared them against core features. A total of 8 similarity metrics against 5 core features were evaluated through a matrix table, and the results indicated that cosine similarity is most suitable for solving the dimensionality issues and lower computational complexity.",
isbn="978-981-97-5703-9"
}

